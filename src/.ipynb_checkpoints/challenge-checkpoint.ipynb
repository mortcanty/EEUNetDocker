{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from osgeo import gdal\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "#from sklearn.metrics import jaccard_score\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn import tree\n",
    "#from sklearn.tree import export_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SETUP'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'system' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e8042f4bb1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mroot_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SETUP\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0min_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SETUP\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/configparser.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_section\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_section\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proxies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SETUP'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e8042f4bb1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'system' is not defined"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"setup.cfg\")\n",
    "try:\n",
    "    root_path = config[\"SETUP\"][\"root\"]\n",
    "    in_path = config[\"SETUP\"][\"in_path\"].split(\",\")\n",
    "    in_path_labels = config[\"SETUP\"][\"in_path_labels\"]\n",
    "    train_data = config[\"DATA\"][\"train_data\"].split(\"\\n\")\n",
    "    val_data = config[\"DATA\"][\"val_data\"].split(\"\\n\")\n",
    "    test_data = config[\"DATA\"][\"test_data\"].split(\"\\n\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    system.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(labels_pred, labels_inp):\n",
    "    score = 0\n",
    "    for i in range(len(labels_pred)):\n",
    "        if labels_pred[i] == labels_inp[i]:\n",
    "            score = score + 1\n",
    "    return score/len(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainingData(root_path, in_path, in_path_labels, training_data, plt_images=False):\n",
    "    training_data_set = []\n",
    "    training_data_labels = []\n",
    "    t = 0\n",
    "    for area in training_data:\n",
    "        data_path = os.path.join(root_path, in_path[0], area, in_path[1])\n",
    "        # only first data set\n",
    "        t = t + 1 \n",
    "        if (t==2):\n",
    "            break\n",
    "        file_list = os.listdir(data_path)\n",
    "        file_list.sort()\n",
    "        label_list = os.listdir(os.path.join(root_path, in_path_labels, area.replace(\"/\",\"_\")))\n",
    "        label_list.sort()\n",
    "        for i in range(0,len(file_list)-8,5):\n",
    "            image1 = \"/\".join([data_path,file_list[i]])\n",
    "            image2 = \"/\".join([data_path,file_list[i+5]])\n",
    "            t_1 = image1.split(\".\")[0].split(\"/\")[-1].split(\"-\")[-3:]\n",
    "            print(t_1)\n",
    "            t_2 = image2.split(\".\")[0].split(\"/\")[-1].split(\"-\")[-3:]\n",
    "            print(t_2)\n",
    "            label = os.path.join(root_path, in_path_labels, area.replace(\"/\",\"_\"))+\"/\"+area.replace(\"/\",\"_\")+\"-\"+\"-\".join(t_2[:2])+\"-\"+\"-\".join(t_1[:2])+\".png\"\n",
    "            print(label)\n",
    "            label_image = np.array(Image.open(label))\n",
    "            print(label_image.max())\n",
    "            training_data_labels.append(label_image)\n",
    "            img1 = gdal.Open(image1)\n",
    "            img2 = gdal.Open(image2)\n",
    "            img1_array = np.zeros((1024,1024,img1.RasterCount))\n",
    "            img2_array = np.zeros((1024,1024,img2.RasterCount))\n",
    "            for j in range(img1.RasterCount):\n",
    "                img1_array[:,:,3-j] = np.array(img1.GetRasterBand(j+1).ReadAsArray())\n",
    "                img2_array[:,:,3-j] = np.array(img2.GetRasterBand(j+1).ReadAsArray())\n",
    "            if plt_images:\n",
    "                img1_array = (img1_array-img1_array.min())/(img1_array.max()-img1_array.min())\n",
    "                img2_array = (img2_array-img2_array.min())/(img2_array.max()-img2_array.min())\n",
    "                plt.imshow(img1_array[:,:,1:4])\n",
    "                plt.show()\n",
    "                plt.imshow(img2_array[:,:,1:4])\n",
    "                plt.show()\n",
    "            merge_arr = np.concatenate((img1_array,img2_array),axis=2)\n",
    "            #merge_arr = img2_array-img1_array\n",
    "            training_data_set.append(merge_arr)\n",
    "    return training_data_set, training_data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_model():\n",
    "    initializer = 'he_normal'\n",
    "    inputs = tf.keras.layers.Input(shape=(256,256,8))\n",
    "    conv11 = tf.keras.layers.Conv2D(64,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(inputs)\n",
    "    conv12 = tf.keras.layers.Conv2D(64,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv11)\n",
    "    max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1),padding=\"same\")(conv12)\n",
    "    conv21 = tf.keras.layers.Conv2D(128,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(max_pool1)\n",
    "    conv22 = tf.keras.layers.Conv2D(128,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv21)\n",
    "    max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1),padding=\"same\")(conv22)\n",
    "    conv31 = tf.keras.layers.Conv2D(256,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(max_pool2)\n",
    "    conv32 = tf.keras.layers.Conv2D(256,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv31)\n",
    "    max_pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1),padding=\"same\")(conv32)\n",
    "    conv41 = tf.keras.layers.Conv2D(512,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(max_pool3)\n",
    "    conv42 = tf.keras.layers.Conv2D(512,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv41)\n",
    "    max_pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1),padding=\"same\")(conv42)\n",
    "    conv51 = tf.keras.layers.Conv2D(1024,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(max_pool4)\n",
    "    conv52 = tf.keras.layers.Conv2D(1024,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv51)\n",
    "    uconv51 = tf.keras.layers.Conv2D(512,2,activation=\"relu\",padding=\"same\")(conv52)\n",
    "    merge_dec5 = tf.keras.layers.concatenate([conv42,uconv51],axis=3)\n",
    "    conv_dec_41 = tf.keras.layers.Conv2D(512,3,activation=\"relu\",padding=\"same\")(merge_dec5)\n",
    "    conv_dec_42 = tf.keras.layers.Conv2D(512,3,activation=\"relu\",padding=\"same\")(conv_dec_41)\n",
    "    uconv41 = tf.keras.layers.Conv2D(256,2,activation=\"relu\",padding=\"same\")(conv_dec_42)\n",
    "    merge_dec4 = tf.keras.layers.concatenate([conv32,uconv41],axis=3)\n",
    "    conv_dec_31 = tf.keras.layers.Conv2D(256,3,activation=\"relu\",padding=\"same\")(merge_dec4)\n",
    "    conv_dec_32 = tf.keras.layers.Conv2D(256,3,activation=\"relu\",padding=\"same\")(conv_dec_31)\n",
    "    uconv31 = tf.keras.layers.Conv2D(128,2,activation=\"relu\",padding=\"same\")(conv_dec_32)\n",
    "    merge_dec3 = tf.keras.layers.concatenate([conv22,uconv31],axis=3)\n",
    "    conv_dec_21 = tf.keras.layers.Conv2D(128,3,activation=\"relu\",padding=\"same\")(merge_dec3)\n",
    "    conv_dec_22 = tf.keras.layers.Conv2D(128,3,activation=\"relu\",padding=\"same\")(conv_dec_21)\n",
    "    uconv21 = tf.keras.layers.Conv2D(64,2,activation=\"relu\",padding=\"same\")(conv_dec_22)\n",
    "    merge_dec2 = tf.keras.layers.concatenate([conv12,uconv21],axis=3)\n",
    "    conv_dec_11 = tf.keras.layers.Conv2D(64,3,activation=\"relu\",padding=\"same\")(merge_dec2)\n",
    "    conv_dec_12 = tf.keras.layers.Conv2D(64,3,activation=\"relu\",padding=\"same\")(conv_dec_11)\n",
    "    conv_dec_12 = tf.keras.layers.Conv2D(8,3,activation=\"relu\",padding=\"same\")(conv_dec_12)\n",
    "    output = tf.keras.layers.Conv2D(num_classes,1,activation = 'softmax')(conv_dec_12)\n",
    "    return tf.keras.Model(inputs = inputs, outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUNetModified():\n",
    "    initializer = 'he_normal'\n",
    "    inp_img1 = Input(shape=(256,256,4),name = 'image1')\n",
    "    inp_img2 = Input(shape=(256,256,4),name = 'image2')\n",
    "    conv_img1_1 = Conv2D(64,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(inp_img1)\n",
    "    conv_img1_1 = Conv2D(64,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img1_1)\n",
    "    conv_img2_1 = Conv2D(64,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(inp_img2)\n",
    "    conv_img2_1 = Conv2D(64,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img2_1)\n",
    "    diff_img1 = Subtract()([conv_img1_1,conv_img2_1])\n",
    "    abs_img1 = Lambda(lambda x: tf.math.abs(x))(diff_img1)\n",
    "    abs_img1 = ThresholdedReLU(theta = 0.2)(abs_img1)\n",
    "\n",
    "    max_pool_img1_1 = MaxPooling2D(pool_size=(3, 3),strides=(1, 1),padding=\"same\")(conv_img1_1)\n",
    "    max_pool_img2_1 = MaxPooling2D(pool_size=(3, 3),strides=(1, 1),padding=\"same\")(conv_img2_1)\n",
    "    conv_img1_2 = Conv2D(128,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(max_pool_img1_1)\n",
    "    conv_img1_2 = Conv2D(128,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img1_2)\n",
    "    conv_img2_2 = Conv2D(128,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(max_pool_img2_1)\n",
    "    conv_img2_2 = Conv2D(128,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img2_2)\n",
    "    diff_img2 = Subtract()([conv_img1_2,conv_img2_2])\n",
    "    abs_img2 = Lambda(lambda x: tf.math.abs(x))(diff_img2)\n",
    "    abs_img2 = ThresholdedReLU(theta = 0.4)(abs_img2)\n",
    "\n",
    "\n",
    "    max_pool_img1_2 = MaxPooling2D(pool_size=(3, 3),strides=(1, 1),padding=\"same\")(conv_img1_2)\n",
    "    max_pool_img2_2 = MaxPooling2D(pool_size=(3, 3),strides=(1, 1),padding=\"same\")(conv_img2_2)\n",
    "    conv_img1_3 = Conv2D(256,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(max_pool_img1_2)\n",
    "    conv_img1_3 = Conv2D(256,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img1_3)\n",
    "    conv_img2_3 = Conv2D(256,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(max_pool_img2_2)\n",
    "    conv_img2_3 = Conv2D(256,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img2_3)\n",
    "    diff_img3 = Subtract()([conv_img1_3,conv_img2_3])\n",
    "    abs_img3 = Lambda(lambda x: tf.math.abs(x))(diff_img3)\n",
    "    abs_img3 = ThresholdedReLU(theta = 0.4)(abs_img3)\n",
    "\n",
    "    uconv_img2_1 = Conv2D(128,3,activation=\"relu\",padding=\"same\")(abs_img3)\n",
    "    merge_dec1 = concatenate([uconv_img2_1,abs_img2],axis=3)\n",
    "    conv_img2_1_up = Conv2D(128,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(merge_dec1) \n",
    "    conv_img2_1_up = Conv2D(128,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img2_1_up)\n",
    "    uconv_img2_2 = Conv2D(64,3,activation=\"relu\",padding=\"same\")(conv_img2_1_up)\n",
    "    merge_dec2 = concatenate([uconv_img2_2,abs_img1],axis=3)\n",
    "    conv_img2_2_up = Conv2D(64,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(merge_dec2) \n",
    "    conv_img2_2_up = Conv2D(64,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img2_2_up)\n",
    "    conv_img2_2_up = Conv2D(4,3,activation=\"relu\",padding=\"same\",kernel_initializer=initializer)(conv_img2_2_up)\n",
    "    output = Conv2D(num_classes,1,activation='softmax')(conv_img2_2_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_double(img1, img2, labels, model):\n",
    "    fig, ([ax1,ax2],[ax3,ax4]) = plt.subplots(2,2,sharey=True,sharex=True)\n",
    "    ax1.imshow(img1[:,:,1:4])\n",
    "    ax2.imshow(img2[:,:,1:4])\n",
    "    #pic = (img[:,:,1:4]-img[:,:,1:4].min())/(img[:,:,1:4].max()-img[:,:,1:4].min())\n",
    "    #ax1.imshow(pic)\n",
    "    #ax2.imshow(labels)\n",
    "    inference = model.predict({'image1':np.array([img1[:,:,:]]),'image2':np.array([img2[:,:,:]])})\n",
    "    print(inference.shape)\n",
    "    mask = create_mask(inference)\n",
    "    #print(mask.shape)\n",
    "    ax3.imshow(labels)\n",
    "    ax4.imshow(mask[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_to_numpy(ds_train_labels, ds_train):\n",
    "    # Convert ds_train and ds_train_labels to numpy array\n",
    "    labels_np = np.array(ds_train_labels)\n",
    "    data_np = np.array(ds_train)\n",
    "    data_np_min = data_np.min()\n",
    "    data_np_max = data_np.max()\n",
    "    for i in range(len(data_np)):\n",
    "        data_np[i] = (data_np[i]-data_np_min)/(data_np_max-data_np_min)\n",
    "        labels_np[i] = np.where(labels_np[i]!=0,1,0)\n",
    "    return data_np, labels_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateImageTiles(data, p=256, q=256):\n",
    "    # convert 1024 x 1024 image to 16 images รก 256 x 256\n",
    "    # due to RAM issues\n",
    "    # for images and labels\n",
    "    m = data.shape[1]  #image row size\n",
    "    n = data.shape[2]  #image column size\n",
    "\n",
    "    block_array = []\n",
    "    previous_row = 0\n",
    "    for img_ind in range(len(data)):\n",
    "        for row_block in range(int(m/p)):\n",
    "            previous_row = row_block * p   \n",
    "            previous_column = 0\n",
    "            for column_block in range(int(n/q)):\n",
    "                previous_column = column_block * q\n",
    "                block = data[img_ind,previous_row:previous_row+p,previous_column:previous_column+q]\n",
    "                block_array.append(block)\n",
    "\n",
    "    data_array = np.array(block_array)\n",
    "\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagesPerBatch(batch_size, shuffle_buffer_size, train_dataset, valid_dataset):\n",
    "    train_dataset = train_dataset.shuffle(shuffle_buffer_size).batch(batch_size)\n",
    "    valid_dataset = valid_dataset.batch(batch_size)\n",
    "    #test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018', '01', '01']\n",
      "['2018', '02', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-02-2018-01.png\n",
      "5\n",
      "['2018', '02', '01']\n",
      "['2018', '03', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-03-2018-02.png\n",
      "5\n",
      "['2018', '03', '01']\n",
      "['2018', '04', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-04-2018-03.png\n",
      "6\n",
      "['2018', '04', '01']\n",
      "['2018', '05', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-05-2018-04.png\n",
      "6\n",
      "['2018', '05', '01']\n",
      "['2018', '06', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-06-2018-05.png\n",
      "5\n",
      "['2018', '06', '01']\n",
      "['2018', '07', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-07-2018-06.png\n",
      "6\n",
      "['2018', '07', '01']\n",
      "['2018', '08', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-08-2018-07.png\n",
      "5\n",
      "['2018', '08', '01']\n",
      "['2018', '09', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-09-2018-08.png\n",
      "6\n",
      "['2018', '09', '01']\n",
      "['2018', '10', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-10-2018-09.png\n",
      "3\n",
      "['2018', '10', '01']\n",
      "['2018', '11', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-11-2018-10.png\n",
      "6\n",
      "['2018', '11', '01']\n",
      "['2018', '12', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2018-12-2018-11.png\n",
      "6\n",
      "['2018', '12', '01']\n",
      "['2019', '01', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-01-2018-12.png\n",
      "5\n",
      "['2019', '01', '01']\n",
      "['2019', '02', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-02-2019-01.png\n",
      "5\n",
      "['2019', '02', '01']\n",
      "['2019', '03', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-03-2019-02.png\n",
      "6\n",
      "['2019', '03', '01']\n",
      "['2019', '04', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-04-2019-03.png\n",
      "6\n",
      "['2019', '04', '01']\n",
      "['2019', '05', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-05-2019-04.png\n",
      "6\n",
      "['2019', '05', '01']\n",
      "['2019', '06', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-06-2019-05.png\n",
      "6\n",
      "['2019', '06', '01']\n",
      "['2019', '07', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-07-2019-06.png\n",
      "6\n",
      "['2019', '07', '01']\n",
      "['2019', '08', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-08-2019-07.png\n",
      "5\n",
      "['2019', '08', '01']\n",
      "['2019', '09', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-09-2019-08.png\n",
      "6\n",
      "['2019', '09', '01']\n",
      "['2019', '10', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-10-2019-09.png\n",
      "2\n",
      "['2019', '10', '01']\n",
      "['2019', '11', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-11-2019-10.png\n",
      "5\n",
      "['2019', '11', '01']\n",
      "['2019', '12', '01']\n",
      "/p/scratch/training2105/MESSy2ACCelerator/kirfel1/planet/Labels/44N_5989_3554_13/44N_5989_3554_13-2019-12-2019-11.png\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# list of concatenated images (t t+1)\n",
    "# erster eintrag: bi\n",
    "ds_train, ds_train_labels = generateTrainingData(root_path, in_path, in_path_labels, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np, labels_np = ds_to_numpy(ds_train_labels, ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 1024, 1024)\n",
      "(23, 1024, 1024, 8)\n",
      "1.0\n",
      "0.1651013332215603\n"
     ]
    }
   ],
   "source": [
    "print(labels_np.shape)\n",
    "print(data_np.shape)\n",
    "print(data_np.max())\n",
    "print(data_np.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_labels = None\n",
    "ds_train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = generateImageTiles(data_np)\n",
    "labels_array = generateImageTiles(labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = None\n",
    "labels_np = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into t and t+1 images\n",
    "#data_array1 = data_array[:,:,:,:4]\n",
    "#data_array2 = data_array[:,:,:,4:]\n",
    "#data_array = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = tf.data.Dataset.from_tensor_slices(({'image1': data_array1[0:256], 'image2': data_array2[0:256]},label_array[0:256])) \n",
    "#valid_dataset = tf.data.Dataset.from_tensor_slices(({'image1': data_array1[2:5], 'image2': data_array2[2:5]},label_array[2:5]))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((data_array[0:16,:,:,:], labels_array[0:16]))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((data_array[3:5,:,:,:], labels_array[3:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 8)\n",
      "(256, 256)\n",
      "0.1276470052213051\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_dataset:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    print(np.mean(image_batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((256, 256, 8), (256, 256)), types: (tf.float64, tf.uint8)>\n",
      "tf.Tensor(16, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(tf.data.experimental.cardinality(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = imagesPerBatch(1, 16, train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(16, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.data.experimental.cardinality(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n",
      "4 Physical GPUs, [LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU'), LogicalDevice(name='/device:GPU:2', device_type='GPU'), LogicalDevice(name='/device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\",logical_gpus)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 8) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 4672        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 128 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 256 590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 256, 256, 256 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 512 1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 512 2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 256, 256, 512 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 102 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 256, 102 9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 256, 256, 512 2097664     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 256, 102 0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 256, 256, 512 4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 256, 512 2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 256, 256 524544      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 512 0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 256 1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 256 590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 128 131200      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 128 147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 8)  4616        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 2)  18          conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,039,194\n",
      "Trainable params: 31,039,194\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = get_unet_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/16 [==>...........................] - ETA: 3s - loss: 0.3373 - accuracy: 0.9922WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2017s vs `on_train_batch_end` time: 0.3085s). Check your callbacks.\n",
      "16/16 [==============================] - 8s 477ms/step - loss: 0.1063 - accuracy: 0.9950\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 8s 495ms/step - loss: 0.0642 - accuracy: 0.9960\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 8s 497ms/step - loss: 0.0642 - accuracy: 0.9960\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 8s 495ms/step - loss: 0.0642 - accuracy: 0.9960\n",
      "Epoch 5/20\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0684 - accuracy: 0.9958"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-791bae87a88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/p/software/juwels/stages/2020/software/TensorFlow/2.3.1-gcccoremkl-9.3.0-2020.2.254-Python-3.8.5/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
